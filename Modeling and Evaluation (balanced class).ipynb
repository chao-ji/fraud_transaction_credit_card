{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continued from **Part 1 Exploratory Data Analysis**\n",
    "\n",
    "In this part, we'll undersample the majority class to achieve class balanceness. Then we'll evaluate a simple logistic regression model in Spark ML on the balanced dataset, and use **CrossValidator** to find the optimal hyperparameter of the regularization coefficient of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"creditcard.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast the columns into float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = [col.name for col in df.schema.fields]\n",
    "for col in colnames[:-1]:\n",
    "    df = df.withColumn(col, df[col].cast(\"float\"))\n",
    "    \n",
    "df = df.withColumn(\"Class\", df[\"Class\"].cast(\"int\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284807"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersample the majority (negative) class to reach class balanceness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = df.filter(df[\"Class\"] == 1)\n",
    "neg = df.filter(df[\"Class\"] == 0)\n",
    "ratio = pos.count() / float(neg.count())\n",
    "neg = neg.sample(False, ratio, seed=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 492\n"
     ]
    }
   ],
   "source": [
    "print pos.count(), neg.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine positive and negative class and split into training and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pos.union(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the \"Class\" column to \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Time: float, V1: float, V2: float, V3: float, V4: float, V5: float, V6: float, V7: float, V8: float, V9: float, V10: float, V11: float, V12: float, V13: float, V14: float, V15: float, V16: float, V17: float, V18: float, V19: float, V20: float, V21: float, V22: float, V23: float, V24: float, V25: float, V26: float, V27: float, V28: float, Amount: float, label: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.withColumnRenamed(\"Class\", \"label\")\n",
    "data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 80%, 20% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create pipeline that first assemble the individual features into vectors.\n",
    "2. Standardize the matrix with zero mean and unit standar deviation.\n",
    "3. Set the hyperparameter grid using **ParamGridBuilder**, and pick the optimal value using cross validator.\n",
    "4. Finally trains the logistic regression model with the best hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|      scaledFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|[-1.8098657196564...|[0.42361902702795...|[0.60434892609849...|       0.0|\n",
      "|[-1.7262448521327...|[-1.7793239514363...|[0.14438663246663...|       1.0|\n",
      "|[-1.6733478422005...|[-6.2695318793994...|[0.00188953747081...|       1.0|\n",
      "|[-1.6615067920374...|[-8.7233346596918...|[1.62717109406233...|       1.0|\n",
      "|[-1.6589709211175...|[-6.2742962258405...|[0.00188057336040...|       1.0|\n",
      "|[-1.6433994162127...|[-11.273167198346...|[1.27092573138424...|       1.0|\n",
      "|[-1.6297979267333...|[-4.5938554014997...|[0.01001252580054...|       1.0|\n",
      "|[-1.5864785449860...|[-14.554455919204...|[4.77617135662524...|       1.0|\n",
      "|[-1.5759159090883...|[-8.6646395354148...|[1.72551968142148...|       1.0|\n",
      "|[-1.5600300400199...|[-4.4867948667480...|[0.01113136313631...|       1.0|\n",
      "|[-1.4525803688936...|[-17.681500614661...|[2.09421777873815...|       1.0|\n",
      "|[-1.4055934052375...|[-17.206687034985...|[3.36690416010944...|       1.0|\n",
      "|[-1.3911536113218...|[-16.520647284522...|[6.68611770519725...|       1.0|\n",
      "|[-1.2909762311806...|[-9.1707921110487...|[1.04023248586091...|       1.0|\n",
      "|[-1.2638989978873...|[-8.5181394664474...|[1.99770918115307...|       1.0|\n",
      "|[-1.2574021385057...|[-7.9435052735385...|[3.54834111015588...|       1.0|\n",
      "|[-1.2499831442442...|[-6.7451002424136...|[0.00117524789231...|       1.0|\n",
      "|[-1.2191544985983...|[-5.5178125596179...|[0.00399856735758...|       1.0|\n",
      "|[-1.2184419398274...|[-5.3180766227332...|[0.00487825931937...|       1.0|\n",
      "|[-1.2171216103402...|[-4.9186035444416...|[0.00725629223799...|       1.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=colnames[:-1],\n",
    "                            outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "lr = LogisticRegression(maxIter=10, featuresCol=\"scaledFeatures\",\n",
    "                        regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [1.0, 0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=10)  # use 3+ folds in practice\n",
    "\n",
    "cvModel = crossval.fit(train)\n",
    "testPred = cvModel.transform(test)\n",
    "testPred.select([\"scaledFeatures\", \"rawPrediction\", \"probability\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark ML only supports **area under ROC** and **area under Precision-Recall curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labelCol: label column name. (default: label)\\nmetricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)\\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under PR: 0.990618570644\n",
      "Area under ROC: 0.986575572336\n"
     ]
    }
   ],
   "source": [
    "print \"Area under PR:\", evaluator.evaluate(testPred,\n",
    "                                           {evaluator.labelCol: \"label\", evaluator.metricName: \"areaUnderPR\"})\n",
    "print \"Area under ROC:\", evaluator.evaluate(testPred,\n",
    "                                            {evaluator.labelCol: \"label\", evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy, precision, recall manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binary_classification_eval(df):\n",
    "    acc = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1. if x[0] == x[1] else 0.).mean()\n",
    "    \n",
    "    precision = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1. if (x[0] == 1) and (x[1] == 1) else 0.).sum()/\\\n",
    "    df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1. if x[0] == 1 else 0.).sum()\n",
    "    \n",
    "    recall = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1. if (x[0] == 1) and (x[1] == 1) else 0.).sum()/\\\n",
    "    df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1. if x[1] == 1 else 0.).sum()\n",
    "    \n",
    "    return {\"accuracy\":acc, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.8640776699029126, 'precision': 1.0, 'accuracy': 0.9239130434782609}\n"
     ]
    }
   ],
   "source": [
    "print binary_classification_eval(testPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(df):\n",
    "    cm = np.zeros((2, 2))\n",
    "    cm[0, 0] = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1 if x[0] == 1 and x[1] == 1 else 0).sum()\n",
    "    cm[0, 1] = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1 if x[0] == 0 and x[1] == 1 else 0).sum()\n",
    "    cm[1, 1] = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1 if x[0] == 0 and x[1] == 0 else 0).sum()\n",
    "    cm[1, 0] = df.select([\"prediction\", \"label\"]).rdd.map(lambda x: 1 if x[0] == 1 and x[1] == 0 else 0).sum()\n",
    "    cm = pd.DataFrame(cm)\n",
    "    cm.index = [\"T\", \"F\"]\n",
    "    cm.index.name = \"Target\"\n",
    "    cm.columns = [\"T\", \"F\"]\n",
    "    cm.columns.name = \"Predicted\"\n",
    "    cm = cm.applymap(int)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>T</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   T   F\n",
       "Target           \n",
       "T          89  14\n",
       "F           0  81"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testPred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
