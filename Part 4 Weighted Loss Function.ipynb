{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we have explored multiple ways to address the class unbalanceness (average predictions of multiple models, boosting, etc.). In this part, we'll try another popular method that assigns different weights to the terms in the **loss function for different class** (depending on majority or minority class)\n",
    "\n",
    "Again we'll train simple logistic regression, with **softmax function** (multinomial) rather than sigmoid function. We'll use tensorflow to control the weighting of different terms in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\", header=0, sep=\",\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Time', u'V1', u'V2', u'V3', u'V4', u'V5', u'V6', u'V7', u'V8', u'V9',\n",
       "       u'V10', u'V11', u'V12', u'V13', u'V14', u'V15', u'V16', u'V17', u'V18',\n",
       "       u'V19', u'V20', u'V21', u'V22', u'V23', u'V24', u'V25', u'V26', u'V27',\n",
       "       u'V28', u'Amount', u'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df[\"Class\"].values\n",
    "data = df.ix[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123, stratify=target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = OneHotEncoder().fit_transform(y_train[:, np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 30]) \n",
    "W = tf.Variable(tf.zeros([30, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.matmul(X, W) + b\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(30)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = y_train[:, 1].sum() / len(y_train)\n",
    "class_weight = tf.constant(np.array([ratio, 1 - ratio]) * 10, dtype=tf.float32)\n",
    "\n",
    "y_weighted = tf.multiply(y, class_weight)\n",
    "y_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: Unweighted\n",
      "Confusion matrix:\n",
      "Predicted      T   F\n",
      "Target              \n",
      "T          56855   9\n",
      "F             44  54\n",
      "Precision: 0.857143\n",
      "Recall:  0.551020\n",
      "\n",
      "Loss function: Weighted\n",
      "Confusion matrix:\n",
      "Predicted      T   F\n",
      "Target              \n",
      "T          56847  17\n",
      "F             34  64\n",
      "Precision: 0.790123\n",
      "Recall:  0.653061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "Epochs = 50\n",
    "learning_rate = 0.5\n",
    "splits = 10 # Split training set into `splits` for training in each epoch\n",
    "\n",
    "for logits, name in zip((y, y_weighted), (\"Unweighted\", \"Weighted\")):\n",
    "    print \"Loss function:\", name\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for _ in range(Epochs):\n",
    "        index_list = np.array_split(range(len(X_train)), splits)\n",
    "        for index in index_list:\n",
    "            sess.run(train_step, feed_dict={X: X_train[index, :], y_: y_train[index, :]})\n",
    "            \n",
    "    y_pred = sess.run(y, feed_dict={X: X_test})\n",
    "    y_pred = np.where(y_pred[:, 1] > y_pred[:, 0], 1, 0)            \n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    cm.index = [\"T\", \"F\"]\n",
    "    cm.index.name = \"Target\"\n",
    "    cm.columns = [\"T\", \"F\"]\n",
    "    cm.columns.name = \"Predicted\"\n",
    "    \n",
    "    print \"Confusion matrix:\"\n",
    "    print cm\n",
    "    print \"Precision: %f\" % precision_score(y_test, y_pred)\n",
    "    print \"Recall: % f\" % recall_score(y_test, y_pred)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 30]) \n",
    "W_0 = tf.Variable(tf.zeros([30, 8]))\n",
    "b_0 = tf.Variable(tf.zeros([8]))\n",
    "O_0 = tf.nn.sigmoid(tf.matmul(X, W_0) + b_0)\n",
    "\n",
    "W_1 = tf.Variable(tf.zeros([8, 2]))\n",
    "b_1 = tf.Variable(tf.zeros([2]))\n",
    "y = tf.matmul(O_0, W_1) + b_1\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = y_train[:, 1].sum() / len(y_train)\n",
    "class_weight = tf.constant(np.array([ratio, 1 - ratio]) * 10, dtype=tf.float32)\n",
    "\n",
    "y_weighted = tf.multiply(y, class_weight)\n",
    "y_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "Epochs = 50\n",
    "learning_rate = 0.5\n",
    "splits = 10 # Split training set into `splits` for training in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_weighted))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "tf.global_variables_initializer().run()\n",
    "    \n",
    "for _ in range(Epochs):\n",
    "    index_list = np.array_split(range(len(X_train)), splits)\n",
    "    for index in index_list:\n",
    "        sess.run(train_step, feed_dict={X: X_train[index, :], y_: y_train[index, :]})\n",
    "            \n",
    "y_pred = sess.run(y, feed_dict={X: X_test})\n",
    "y_pred = np.where(y_pred[:, 1] > y_pred[:, 0], 1, 0)            \n",
    "    \n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56837</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  56837  27\n",
       "1     25  73"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72999999999999998"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74489795918367352"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
