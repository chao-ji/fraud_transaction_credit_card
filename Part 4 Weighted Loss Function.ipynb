{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we have explored multiple ways to address the class unbalanceness (average predictions of multiple models, boosting, etc.). In this part, we'll try another popular method that assigns different weights to the terms in the **loss function for different class** (depending on majority or minority class)\n",
    "\n",
    "Again we'll train simple logistic regression, with **softmax function** (multinomial) rather than **sigmoid function**. We'll use tensorflow to control the weighting of different terms in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\", header=0, sep=\",\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Time', u'V1', u'V2', u'V3', u'V4', u'V5', u'V6', u'V7', u'V8', u'V9',\n",
       "       u'V10', u'V11', u'V12', u'V13', u'V14', u'V15', u'V16', u'V17', u'V18',\n",
       "       u'V19', u'V20', u'V21', u'V22', u'V23', u'V24', u'V25', u'V26', u'V27',\n",
       "       u'V28', u'Amount', u'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data and target labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df[\"Class\"].values\n",
    "data = df.ix[:, :-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split all data into training and test set\n",
    "2. Scale the **X** of training and test set\n",
    "3. Turn the target labels into one-hot representation for softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123, stratify=target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = OneHotEncoder().fit_transform(y_train[:, np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the one-layer neural network (just the output layer with softmax function):\n",
    "\n",
    "$y_{2,} = X_{batch, 30} \\cdot W_{30, 2} + b_{2,}$, where $y_{2,}$ is a 1-D tensor with two components for positive and negative class, on which softmax function will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 30]) \n",
    "W = tf.Variable(tf.zeros([30, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "y = tf.matmul(X, W) + b\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(30)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll optionally weight $y_{2,}$ with the majority class being down-weighted, and minority class being up-weighted. We want to assign much bigger cost when the positive class is classified as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.1\n",
    "class_weight = tf.constant(np.array([ratio, 1 - ratio]) * 10, dtype=tf.float32)\n",
    "\n",
    "y_weighted = tf.multiply(y, class_weight)\n",
    "y_weighted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the process with unweighted and weighted loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: Unweighted\n",
      "Confusion matrix:\n",
      "Predicted      T   F\n",
      "Target              \n",
      "T          56855   9\n",
      "F             44  54\n",
      "Precision: 0.857143\n",
      "Recall:  0.551020\n",
      "\n",
      "Loss function: Weighted\n",
      "Confusion matrix:\n",
      "Predicted      T   F\n",
      "Target              \n",
      "T          56848  16\n",
      "F             34  64\n",
      "Precision: 0.800000\n",
      "Recall:  0.653061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "Epochs = 50\n",
    "learning_rate = 0.5\n",
    "splits = 10 # Split training set into `splits` for training in each epoch\n",
    "\n",
    "for logits, name in zip((y, y_weighted), (\"Unweighted\", \"Weighted\")):\n",
    "    print \"Loss function:\", name\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits))\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for _ in range(Epochs):\n",
    "        index_list = np.array_split(range(len(X_train)), splits)\n",
    "        for index in index_list:\n",
    "            sess.run(train_step, feed_dict={X: X_train[index, :], y_: y_train[index, :]})\n",
    "            \n",
    "    y_pred = sess.run(y, feed_dict={X: X_test})\n",
    "    y_pred = np.where(y_pred[:, 1] > y_pred[:, 0], 1, 0)            \n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    cm.index = [\"T\", \"F\"]\n",
    "    cm.index.name = \"Target\"\n",
    "    cm.columns = [\"T\", \"F\"]\n",
    "    cm.columns.name = \"Predicted\"\n",
    "    \n",
    "    print \"Confusion matrix:\"\n",
    "    print cm\n",
    "    print \"Precision: %f\" % precision_score(y_test, y_pred)\n",
    "    print \"Recall: % f\" % recall_score(y_test, y_pred)\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, when the loss function is weighted depending on the majority and minority class, the recall has increased by 18.5%, while the precision only decreased by 6.7%\n",
    "\n",
    "This means the algorithm is forced to learn the importance of different classes.\n",
    "\n",
    "### Multi-Layer Perceptron\n",
    "Nest, we add a hidden layer of 8 units:\n",
    "\n",
    "$$O_{8,} = sigmoid(X_{batch, 30} \\cdot W_{30, 8} + b_{8,})$$\n",
    "$$y = O_{8,} \\cdot W_{8, 2} + b_{2,}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 30]) \n",
    "#W_0 = tf.Variable(tf.truncated_normal([30, 8], stddev=0.05))\n",
    "W_0 = tf.Variable(tf.zeros([30, 8]))\n",
    "#b_0 = tf.Variable(tf.truncated_normal([8], stddev=0.05))\n",
    "b_0 = tf.Variable(tf.zeros([8]))\n",
    "O_0 = tf.nn.sigmoid(tf.matmul(X, W_0) + b_0)\n",
    "\n",
    "#W_1 = tf.Variable(tf.truncated_normal([8, 2], stddev=0.05))\n",
    "W_1 = tf.Variable(tf.zeros([8, 2]))\n",
    "#b_1 = tf.Variable(tf.truncated_normal([2], stddev=0.05))\n",
    "b_1 = tf.Variable(tf.zeros([2]))\n",
    "y = tf.matmul(O_0, W_1) + b_1\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.1\n",
    "class_weight = tf.constant(np.array([ratio, 1 - ratio]) * 10, dtype=tf.float32)\n",
    "\n",
    "y_weighted = tf.multiply(y, class_weight)\n",
    "y_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "Epochs = 50\n",
    "learning_rate = 0.5\n",
    "splits = 10 # Split training set into `splits` for training in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_weighted))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "tf.global_variables_initializer().run()\n",
    "    \n",
    "for _ in range(Epochs):\n",
    "    index_list = np.array_split(range(len(X_train)), splits)\n",
    "    for index in index_list:\n",
    "        sess.run(train_step, feed_dict={X: X_train[index, :], y_: y_train[index, :]})\n",
    "            \n",
    "y_pred = sess.run(y, feed_dict={X: X_test})\n",
    "y_pred = np.where(y_pred[:, 1] > y_pred[:, 0], 1, 0)            \n",
    "    \n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "cm.index = [\"T\", \"F\"]\n",
    "cm.index.name = \"Target\"\n",
    "cm.columns = [\"T\", \"F\"]\n",
    "cm.columns.name = \"Predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>T</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>56837</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      T   F\n",
       "Target              \n",
       "T          56837  27\n",
       "F             26  72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72727272727272729"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73469387755102045"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The new two-layer neural network achived even better trade-off between precision and recall. Ideally, we want the recall to be in the range of 0.95 ~ 1.0, while maintaining precision at an acceptable level."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
